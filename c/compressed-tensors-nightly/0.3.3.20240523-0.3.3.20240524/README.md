# Comparing `tmp/compressed_tensors_nightly-0.3.3.20240523-py3-none-any.whl.zip` & `tmp/compressed_tensors_nightly-0.3.3.20240524-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,45 @@
-Zip file size: 63783 bytes, number of entries: 43
--rw-r--r--  2.0 unx      789 b- defN 24-May-23 00:03 compressed_tensors/__init__.py
--rw-r--r--  2.0 unx      755 b- defN 24-May-23 00:03 compressed_tensors/base.py
--rw-r--r--  2.0 unx     1512 b- defN 24-May-23 00:03 compressed_tensors/version.py
--rw-r--r--  2.0 unx      992 b- defN 24-May-23 00:03 compressed_tensors/compressors/__init__.py
--rw-r--r--  2.0 unx     2134 b- defN 24-May-23 00:03 compressed_tensors/compressors/base.py
--rw-r--r--  2.0 unx     1257 b- defN 24-May-23 00:03 compressed_tensors/compressors/dense.py
--rw-r--r--  2.0 unx     5403 b- defN 24-May-23 00:03 compressed_tensors/compressors/helpers.py
--rw-r--r--  2.0 unx     4744 b- defN 24-May-23 00:03 compressed_tensors/compressors/int_quantized.py
--rw-r--r--  2.0 unx    10426 b- defN 24-May-23 00:03 compressed_tensors/compressors/model_compressor.py
--rw-r--r--  2.0 unx     7885 b- defN 24-May-23 00:03 compressed_tensors/compressors/pack_quantized.py
--rw-r--r--  2.0 unx     8637 b- defN 24-May-23 00:03 compressed_tensors/compressors/sparse_bitmask.py
--rw-r--r--  2.0 unx      704 b- defN 24-May-23 00:03 compressed_tensors/config/__init__.py
--rw-r--r--  2.0 unx     1454 b- defN 24-May-23 00:03 compressed_tensors/config/base.py
--rw-r--r--  2.0 unx     1317 b- defN 24-May-23 00:03 compressed_tensors/config/dense.py
--rw-r--r--  2.0 unx     1308 b- defN 24-May-23 00:03 compressed_tensors/config/sparse_bitmask.py
--rw-r--r--  2.0 unx      760 b- defN 24-May-23 00:03 compressed_tensors/quantization/__init__.py
--rw-r--r--  2.0 unx     4360 b- defN 24-May-23 00:03 compressed_tensors/quantization/quant_args.py
--rw-r--r--  2.0 unx     8727 b- defN 24-May-23 00:03 compressed_tensors/quantization/quant_config.py
--rw-r--r--  2.0 unx     3341 b- defN 24-May-23 00:03 compressed_tensors/quantization/quant_scheme.py
--rw-r--r--  2.0 unx      798 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/__init__.py
--rw-r--r--  2.0 unx     7625 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/apply.py
--rw-r--r--  2.0 unx     1776 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/calibration.py
--rw-r--r--  2.0 unx     2247 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/compressed.py
--rw-r--r--  2.0 unx    10520 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/forward.py
--rw-r--r--  2.0 unx     1726 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/frozen.py
--rw-r--r--  2.0 unx     3697 b- defN 24-May-23 00:03 compressed_tensors/quantization/lifecycle/initialize.py
--rw-r--r--  2.0 unx      745 b- defN 24-May-23 00:03 compressed_tensors/quantization/observers/__init__.py
--rw-r--r--  2.0 unx     5121 b- defN 24-May-23 00:03 compressed_tensors/quantization/observers/base.py
--rw-r--r--  2.0 unx     2166 b- defN 24-May-23 00:03 compressed_tensors/quantization/observers/helpers.py
--rw-r--r--  2.0 unx     2165 b- defN 24-May-23 00:03 compressed_tensors/quantization/observers/memoryless.py
--rw-r--r--  2.0 unx     3669 b- defN 24-May-23 00:03 compressed_tensors/quantization/observers/min_max.py
--rw-r--r--  2.0 unx      656 b- defN 24-May-23 00:03 compressed_tensors/quantization/utils/__init__.py
--rw-r--r--  2.0 unx     6017 b- defN 24-May-23 00:03 compressed_tensors/quantization/utils/helpers.py
--rw-r--r--  2.0 unx      658 b- defN 24-May-23 00:03 compressed_tensors/registry/__init__.py
--rw-r--r--  2.0 unx    11890 b- defN 24-May-23 00:03 compressed_tensors/registry/registry.py
--rw-r--r--  2.0 unx      665 b- defN 24-May-23 00:03 compressed_tensors/utils/__init__.py
--rw-r--r--  2.0 unx     1735 b- defN 24-May-23 00:03 compressed_tensors/utils/helpers.py
--rw-r--r--  2.0 unx     8502 b- defN 24-May-23 00:03 compressed_tensors/utils/safetensors_load.py
--rw-r--r--  2.0 unx    11357 b- defN 24-May-23 00:05 compressed_tensors_nightly-0.3.3.20240523.dist-info/LICENSE
--rw-r--r--  2.0 unx     5633 b- defN 24-May-23 00:05 compressed_tensors_nightly-0.3.3.20240523.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-23 00:05 compressed_tensors_nightly-0.3.3.20240523.dist-info/WHEEL
--rw-r--r--  2.0 unx       19 b- defN 24-May-23 00:05 compressed_tensors_nightly-0.3.3.20240523.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4376 b- defN 24-May-23 00:05 compressed_tensors_nightly-0.3.3.20240523.dist-info/RECORD
-43 files, 160360 bytes uncompressed, 56515 bytes compressed:  64.8%
+Zip file size: 64187 bytes, number of entries: 43
+-rw-r--r--  2.0 unx      789 b- defN 24-May-24 00:04 compressed_tensors/__init__.py
+-rw-r--r--  2.0 unx      755 b- defN 24-May-24 00:04 compressed_tensors/base.py
+-rw-r--r--  2.0 unx     1512 b- defN 24-May-24 00:04 compressed_tensors/version.py
+-rw-r--r--  2.0 unx      992 b- defN 24-May-24 00:04 compressed_tensors/compressors/__init__.py
+-rw-r--r--  2.0 unx     2134 b- defN 24-May-24 00:04 compressed_tensors/compressors/base.py
+-rw-r--r--  2.0 unx     1257 b- defN 24-May-24 00:04 compressed_tensors/compressors/dense.py
+-rw-r--r--  2.0 unx     5403 b- defN 24-May-24 00:04 compressed_tensors/compressors/helpers.py
+-rw-r--r--  2.0 unx     5203 b- defN 24-May-24 00:04 compressed_tensors/compressors/int_quantized.py
+-rw-r--r--  2.0 unx    10481 b- defN 24-May-24 00:04 compressed_tensors/compressors/model_compressor.py
+-rw-r--r--  2.0 unx     8344 b- defN 24-May-24 00:04 compressed_tensors/compressors/pack_quantized.py
+-rw-r--r--  2.0 unx     8637 b- defN 24-May-24 00:04 compressed_tensors/compressors/sparse_bitmask.py
+-rw-r--r--  2.0 unx      704 b- defN 24-May-24 00:04 compressed_tensors/config/__init__.py
+-rw-r--r--  2.0 unx     1454 b- defN 24-May-24 00:04 compressed_tensors/config/base.py
+-rw-r--r--  2.0 unx     1317 b- defN 24-May-24 00:04 compressed_tensors/config/dense.py
+-rw-r--r--  2.0 unx     1308 b- defN 24-May-24 00:04 compressed_tensors/config/sparse_bitmask.py
+-rw-r--r--  2.0 unx      760 b- defN 24-May-24 00:04 compressed_tensors/quantization/__init__.py
+-rw-r--r--  2.0 unx     4360 b- defN 24-May-24 00:04 compressed_tensors/quantization/quant_args.py
+-rw-r--r--  2.0 unx     8727 b- defN 24-May-24 00:04 compressed_tensors/quantization/quant_config.py
+-rw-r--r--  2.0 unx     3571 b- defN 24-May-24 00:04 compressed_tensors/quantization/quant_scheme.py
+-rw-r--r--  2.0 unx      798 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/__init__.py
+-rw-r--r--  2.0 unx     7984 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/apply.py
+-rw-r--r--  2.0 unx     1776 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/calibration.py
+-rw-r--r--  2.0 unx     2247 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/compressed.py
+-rw-r--r--  2.0 unx    10520 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/forward.py
+-rw-r--r--  2.0 unx     1726 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/frozen.py
+-rw-r--r--  2.0 unx     3732 b- defN 24-May-24 00:04 compressed_tensors/quantization/lifecycle/initialize.py
+-rw-r--r--  2.0 unx      745 b- defN 24-May-24 00:04 compressed_tensors/quantization/observers/__init__.py
+-rw-r--r--  2.0 unx     5121 b- defN 24-May-24 00:04 compressed_tensors/quantization/observers/base.py
+-rw-r--r--  2.0 unx     2166 b- defN 24-May-24 00:04 compressed_tensors/quantization/observers/helpers.py
+-rw-r--r--  2.0 unx     2165 b- defN 24-May-24 00:04 compressed_tensors/quantization/observers/memoryless.py
+-rw-r--r--  2.0 unx     3669 b- defN 24-May-24 00:04 compressed_tensors/quantization/observers/min_max.py
+-rw-r--r--  2.0 unx      656 b- defN 24-May-24 00:04 compressed_tensors/quantization/utils/__init__.py
+-rw-r--r--  2.0 unx     6017 b- defN 24-May-24 00:04 compressed_tensors/quantization/utils/helpers.py
+-rw-r--r--  2.0 unx      658 b- defN 24-May-24 00:04 compressed_tensors/registry/__init__.py
+-rw-r--r--  2.0 unx    11890 b- defN 24-May-24 00:04 compressed_tensors/registry/registry.py
+-rw-r--r--  2.0 unx      665 b- defN 24-May-24 00:04 compressed_tensors/utils/__init__.py
+-rw-r--r--  2.0 unx     1735 b- defN 24-May-24 00:04 compressed_tensors/utils/helpers.py
+-rw-r--r--  2.0 unx     8502 b- defN 24-May-24 00:04 compressed_tensors/utils/safetensors_load.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-May-24 00:06 compressed_tensors_nightly-0.3.3.20240524.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5633 b- defN 24-May-24 00:06 compressed_tensors_nightly-0.3.3.20240524.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-24 00:06 compressed_tensors_nightly-0.3.3.20240524.dist-info/WHEEL
+-rw-r--r--  2.0 unx       19 b- defN 24-May-24 00:05 compressed_tensors_nightly-0.3.3.20240524.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4376 b- defN 24-May-24 00:06 compressed_tensors_nightly-0.3.3.20240524.dist-info/RECORD
+43 files, 161957 bytes uncompressed, 56919 bytes compressed:  64.9%
```

## zipnote {}

```diff
@@ -108,23 +108,23 @@
 
 Filename: compressed_tensors/utils/helpers.py
 Comment: 
 
 Filename: compressed_tensors/utils/safetensors_load.py
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240523.dist-info/LICENSE
+Filename: compressed_tensors_nightly-0.3.3.20240524.dist-info/LICENSE
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240523.dist-info/METADATA
+Filename: compressed_tensors_nightly-0.3.3.20240524.dist-info/METADATA
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240523.dist-info/WHEEL
+Filename: compressed_tensors_nightly-0.3.3.20240524.dist-info/WHEEL
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240523.dist-info/top_level.txt
+Filename: compressed_tensors_nightly-0.3.3.20240524.dist-info/top_level.txt
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240523.dist-info/RECORD
+Filename: compressed_tensors_nightly-0.3.3.20240524.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## compressed_tensors/compressors/int_quantized.py

```diff
@@ -74,15 +74,19 @@
                         value = quantize(
                             x=value,
                             scale=scale,
                             zero_point=zp,
                             args=quant_args,
                             dtype=torch.int8,
                         )
-
+            elif name.endswith("zero_point"):
+                if torch.all(value == 0):
+                    # all zero_points are 0, no need to include in
+                    # compressed state_dict
+                    continue
             compressed_dict[name] = value.to("cpu")
 
         return compressed_dict
 
     def decompress(
         self, path_to_model_or_tensors: str, device: str = "cpu"
     ) -> Generator[Tuple[str, Tensor], None, None]:
@@ -102,14 +106,20 @@
         for weight_name in weight_mappings.keys():
             weight_data = {}
             for param_name, safe_path in weight_mappings[weight_name].items():
                 full_name = merge_names(weight_name, param_name)
                 with safe_open(safe_path, framework="pt", device=device) as f:
                     weight_data[param_name] = f.get_tensor(full_name)
 
-            if len(weight_data) == len(self.COMPRESSION_PARAM_NAMES):
+            if "weight_scale" in weight_data:
+                zero_point = weight_data.get("weight_zero_point", None)
+                scale = weight_data["weight_scale"]
+                if zero_point is None:
+                    # zero_point assumed to be 0 if not included in state_dict
+                    zero_point = torch.zeros_like(scale)
+
                 decompressed = dequantize(
                     x_q=weight_data["weight"],
-                    scale=weight_data["weight_scale"],
-                    zero_point=weight_data["weight_zero_point"],
+                    scale=scale,
+                    zero_point=zero_point,
                 )
                 yield merge_names(weight_name, "weight"), decompressed
```

## compressed_tensors/compressors/model_compressor.py

```diff
@@ -245,16 +245,17 @@
         with open(config_file_path, "w") as config_file:
             json.dump(config_data, config_file, indent=2, sort_keys=True)
 
     def _replace_weights(self, dense_weight_generator, model):
         for name, data in tqdm(dense_weight_generator, desc="Decompressing model"):
             # loading the decompressed weights into the model
             model_device = operator.attrgetter(name)(model).device
-            data_new = Parameter(data.to(model_device))
             data_old = operator.attrgetter(name)(model)
+            data_dtype = data_old.dtype
+            data_new = Parameter(data.to(model_device).to(data_dtype))
             data_old.data = data_new.data
 
 
 def _get_weight_arg_mappings(model: Module) -> Dict:
     quantized_modules_to_args = {}
     for name, submodule in iter_named_leaf_modules(model):
         if is_module_quantized(submodule):
```

## compressed_tensors/compressors/pack_quantized.py

```diff
@@ -83,15 +83,19 @@
                             scale=scale,
                             zero_point=zp,
                             args=quant_args,
                             dtype=torch.int8,
                         )
                         value = pack_4bit_ints(value.cpu())
                     compressed_dict[merge_names(prefix, "weight_shape")] = shape
-
+            elif name.endswith("zero_point"):
+                if torch.all(value == 0):
+                    # all zero_points are 0, no need to include in
+                    # compressed state_dict
+                    continue
             compressed_dict[name] = value.to("cpu")
 
         return compressed_dict
 
     def decompress(
         self, path_to_model_or_tensors: str, device: str = "cpu"
     ) -> Generator[Tuple[str, Tensor], None, None]:
@@ -111,22 +115,28 @@
         for weight_name in weight_mappings.keys():
             weight_data = {}
             for param_name, safe_path in weight_mappings[weight_name].items():
                 full_name = merge_names(weight_name, param_name)
                 with safe_open(safe_path, framework="pt", device=device) as f:
                     weight_data[param_name] = f.get_tensor(full_name)
 
-            if len(weight_data) == len(self.COMPRESSION_PARAM_NAMES):
+            if "weight_scale" in weight_data:
+                zero_point = weight_data.get("weight_zero_point", None)
+                scale = weight_data["weight_scale"]
+                if zero_point is None:
+                    # zero_point assumed to be 0 if not included in state_dict
+                    zero_point = torch.zeros_like(scale)
+
                 weight = weight_data["weight"]
                 original_shape = torch.Size(weight_data["weight_shape"])
                 unpacked = unpack_4bit_ints(weight, original_shape)
                 decompressed = dequantize(
                     x_q=unpacked,
-                    scale=weight_data["weight_scale"],
-                    zero_point=weight_data["weight_zero_point"],
+                    scale=scale,
+                    zero_point=zero_point,
                 )
                 yield merge_names(weight_name, "weight"), decompressed
 
 
 def pack_4bit_ints(value: torch.Tensor) -> torch.Tensor:
     """
     Packs a tensor of int4 weights stored in int8 into int32s with padding
```

## compressed_tensors/quantization/quant_scheme.py

```diff
@@ -18,14 +18,15 @@
 from compressed_tensors.quantization.quant_args import QuantizationArgs
 from pydantic import BaseModel
 
 
 __all__ = [
     "QuantizationScheme",
     "preset_name_to_scheme",
+    "is_preset_scheme",
 ]
 
 
 class QuantizationScheme(BaseModel):
     """
     Set of QuantizationArgs defining how the weights, inputs and outputs of target list
     of modules should be quantized
@@ -94,14 +95,22 @@
     scheme_args = deepcopy(PRESET_SCHEMES[name])  # deepcopy to avoid args references
     return QuantizationScheme(
         targets=targets,
         **scheme_args,
     )
 
 
+def is_preset_scheme(name: str) -> bool:
+    """
+    :param name: preset quantization settings name
+    :return: True if the name is a preset scheme name
+    """
+    return name.upper() in PRESET_SCHEMES
+
+
 W8A8 = dict(
     weights=QuantizationArgs(), input_activations=QuantizationArgs(symmetric=False)
 )
 
 W4A16 = dict(weights=QuantizationArgs(num_bits=4, symmetric=False))
 
 PRESET_SCHEMES = {
```

## compressed_tensors/quantization/lifecycle/apply.py

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import re
 from collections import OrderedDict
 from typing import Dict, Iterable, Optional
 
+import torch
 from compressed_tensors.quantization.lifecycle.calibration import (
     set_module_for_calibration,
 )
 from compressed_tensors.quantization.lifecycle.compressed import (
     compress_quantized_weights,
 )
 from compressed_tensors.quantization.lifecycle.frozen import freeze_module_quantization
@@ -189,11 +190,17 @@
     :module: pytorch module associated with module_name
     :state_dict: state_dict to search for matching quantization parameters
     """
     scale_name = f"{base_name}_scale"
     zp_name = f"{base_name}_zero_point"
     device = next(module.parameters()).device
 
-    scale = getattr(module, scale_name)
-    zp = getattr(module, zp_name)
-    scale.data = state_dict[f"{module_name}.{scale_name}"].to(device)
-    zp.data = state_dict[f"{module_name}.{zp_name}"].to(device)
+    scale = getattr(module, scale_name, None)
+    zp = getattr(module, zp_name, None)
+    if scale is not None:
+        scale.data = state_dict[f"{module_name}.{scale_name}"].to(device)
+    if zp is not None:
+        zp_from_state = state_dict.get(f"{module_name}.{zp_name}", None)
+        if zp_from_state is not None:  # load the non-zero zero points
+            zp.data = state_dict[f"{module_name}.{zp_name}"].to(device)
+        else:  # fill with zeros matching scale shape
+            zp.data = torch.zeros_like(scale, dtype=torch.int8).to(device)
```

## compressed_tensors/quantization/lifecycle/initialize.py

```diff
@@ -86,14 +86,16 @@
 
     if quantization_args.dynamic:
         return  # no need to register a scale and zero point for a dynamic observer
 
     device = next(module.parameters()).device
 
     # initializes empty scale and zero point parameters for the module
-    init_scale = Parameter(torch.empty(0, device=device), requires_grad=False)
+    init_scale = Parameter(
+        torch.empty(0, dtype=torch.float16, device=device), requires_grad=False
+    )
     module.register_parameter(f"{base_name}_scale", init_scale)
 
     init_zero_point = Parameter(
         torch.empty(0, device=device, dtype=int), requires_grad=False
     )
     module.register_parameter(f"{base_name}_zero_point", init_zero_point)
```

## Comparing `compressed_tensors_nightly-0.3.3.20240523.dist-info/LICENSE` & `compressed_tensors_nightly-0.3.3.20240524.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `compressed_tensors_nightly-0.3.3.20240523.dist-info/METADATA` & `compressed_tensors_nightly-0.3.3.20240524.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: compressed-tensors-nightly
-Version: 0.3.3.20240523
+Version: 0.3.3.20240524
 Summary: Library for utilization of compressed safetensors of neural network models
 Home-page: https://github.com/neuralmagic/compressed-tensors
 Author: Neuralmagic, Inc.
 Author-email: support@neuralmagic.com
 License: Apache 2.0
 Description-Content-Type: text/markdown
 License-File: LICENSE
```

## Comparing `compressed_tensors_nightly-0.3.3.20240523.dist-info/RECORD` & `compressed_tensors_nightly-0.3.3.20240524.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,43 +1,43 @@
 compressed_tensors/__init__.py,sha256=SV1csvHUVCd8kHXz6UDZim1HZ_fAVG3vfk-j_4Bb6hY,789
 compressed_tensors/base.py,sha256=OA2TOLP1gP3LSH7gp508eqr2ZtDQ-pqRHElCp-aB0vs,755
 compressed_tensors/version.py,sha256=V8krJZctm43D4AGQhJY6dB0MvP1-T9TJ8BcGa8kESrI,1512
 compressed_tensors/compressors/__init__.py,sha256=3yyoNICHll3F4HS6Yu-cgNZpDhfuobFNWCs6DrPcUyQ,992
 compressed_tensors/compressors/base.py,sha256=LWEgbpgTxzmoqQ7Xhq2OQszUgWoDtFuGCiV1Y8nlBGw,2134
 compressed_tensors/compressors/dense.py,sha256=G_XHbvuENyupIKlXSITOQgvPkNkcMEOLcLWQr70V9EE,1257
 compressed_tensors/compressors/helpers.py,sha256=k9avlkmeYj6vkOAvl-MgcixtP7ib24SCfhzZ-RusXfw,5403
-compressed_tensors/compressors/int_quantized.py,sha256=I0FqnjtwCiJvQxi9YyfA8aBeaR5csqtq1bOrVvRqJ1I,4744
-compressed_tensors/compressors/model_compressor.py,sha256=teohd0xTbcIDIuEfZrH-bZyAzHn2UZH2KJXT-7Gk3sw,10426
-compressed_tensors/compressors/pack_quantized.py,sha256=K03l8kFqejpapgcMU5hMm1-JIX1cUVvU-VybGSN6RWA,7885
+compressed_tensors/compressors/int_quantized.py,sha256=bPi62n1MjySOeBat_yWMyc_LvDNDeSihu1gxzo_YrNY,5203
+compressed_tensors/compressors/model_compressor.py,sha256=gHD2VMbXkXaZiJu3ibOaWiYb4oJDz2hxX03wDuu1yhI,10481
+compressed_tensors/compressors/pack_quantized.py,sha256=VFaHQU-f1QuXuTyOtn19p015KHveXe-NeNJ97ATuOR8,8344
 compressed_tensors/compressors/sparse_bitmask.py,sha256=H9oZSTYI1oRCzAMbd4zThUnZd1h2rfs8DmA3tPcvuNE,8637
 compressed_tensors/config/__init__.py,sha256=ZBqWn3r6ku1qfmlHHYp0mQueY0i7Pwhr9rbQk9dDlMc,704
 compressed_tensors/config/base.py,sha256=grf5tDaLep8i2-W_p7H-fW9DOGXDi4Zz7su7zjs1Qqc,1454
 compressed_tensors/config/dense.py,sha256=NgSxnFCnckU9-iunxEaqiFwqgdO7YYxlWKR74jNbjks,1317
 compressed_tensors/config/sparse_bitmask.py,sha256=pZUboRNZTu6NajGOQEFExoPknak5ynVAUeiiYpS1Gt8,1308
 compressed_tensors/quantization/__init__.py,sha256=83J5bPB7PavN2TfCoW7_vEDhfYpm4TDrqYO9vdSQ5bk,760
 compressed_tensors/quantization/quant_args.py,sha256=A6b2V8lhsM8Ho8RjlPBQdxRUDNWhqq-ie5E3RR2_GNg,4360
 compressed_tensors/quantization/quant_config.py,sha256=3BcbQ8-Ah7LbTDSSkRu29Yiid33xo0C1ki6NVhxLiaY,8727
-compressed_tensors/quantization/quant_scheme.py,sha256=QwZsCo8QR9ISB_d58WhIngk2gsMM8ooX-LcRPR-JDRw,3341
+compressed_tensors/quantization/quant_scheme.py,sha256=-hAK1-C67_wJl10eaVLUvbslPBTV04WyzL_J-u9f1ck,3571
 compressed_tensors/quantization/lifecycle/__init__.py,sha256=ggRGWRqhCxCaTTDWRcgTVX3axnS2xV6rc5YvdzK7fSg,798
-compressed_tensors/quantization/lifecycle/apply.py,sha256=whKfNGC_EZm0BC23AP7qWfjRe5OJVWmcZOpX7lryZZc,7625
+compressed_tensors/quantization/lifecycle/apply.py,sha256=yLTDT1zkJp1Nti-aKZGOMW8-TELanF8dXiqDvAkVUQo,7984
 compressed_tensors/quantization/lifecycle/calibration.py,sha256=mLns4jlaWmBwOW8Jtlm5bMX-JET1AiZYUBO7qa-XuxI,1776
 compressed_tensors/quantization/lifecycle/compressed.py,sha256=VreB10xPwgSLQQlTu20UCrFpRS--cA7-lx5s7nrPPrg,2247
 compressed_tensors/quantization/lifecycle/forward.py,sha256=x9JaIX3TK7cb_-0aCOTTYtA4At9l6v5YOY_70GzIeFU,10520
 compressed_tensors/quantization/lifecycle/frozen.py,sha256=h1XYt89MouBTf3jTYLG_6OdFxIu5q2N8tPjsy6J4E6Y,1726
-compressed_tensors/quantization/lifecycle/initialize.py,sha256=U6g9qifSF6pagQZQZEwd-rwWC6uQ_dZXn1wg6nr1Abg,3697
+compressed_tensors/quantization/lifecycle/initialize.py,sha256=pFfcu-pxdQKzlnn-18-RlkEktt2yDi6woNXJsiv1A2c,3732
 compressed_tensors/quantization/observers/__init__.py,sha256=DNH31NQYrIBBcmHsMyFA6whh4pbRsLwuNa6L8AeXaGc,745
 compressed_tensors/quantization/observers/base.py,sha256=kywLVwycFvGxuZMU2cy8-KYyNrZCHkinN6YzCL7boLE,5121
 compressed_tensors/quantization/observers/helpers.py,sha256=JwALNfBYY9Eyl8Q180t0lGh8szumQj8TygfNl-isErs,2166
 compressed_tensors/quantization/observers/memoryless.py,sha256=jH_c6K3gxf4W3VNXQ7tbnP-J_86QTrEfjBn6Kh1C-H8,2165
 compressed_tensors/quantization/observers/min_max.py,sha256=UK7zCMzxv9GGn6BflBxdajV20RiWaCY2RHcvZodCP1w,3669
 compressed_tensors/quantization/utils/__init__.py,sha256=VdtEmP0bvuND_IGQnyqUPc5lnFp-1_yD7StKSX4x80w,656
 compressed_tensors/quantization/utils/helpers.py,sha256=NzAH18Cn_-mTAR87y6IlcQU5gC393XSjgNKC9CRkr78,6017
 compressed_tensors/registry/__init__.py,sha256=FwLSNYqfIrb5JD_6OK_MT4_svvKTN_nEhpgQlQvGbjI,658
 compressed_tensors/registry/registry.py,sha256=fxjOjh2wklCvJhQxwofdy-zV8q7MkQ85SLG77nml2iA,11890
 compressed_tensors/utils/__init__.py,sha256=5DrYjoZbaEvSkJcC-GRSbM_RBHVF4tG9gMd3zsJnjLw,665
 compressed_tensors/utils/helpers.py,sha256=h0jfl9drs5FAx40tCHRcVtJqXixB5hT5yq_IG2aY_-w,1735
 compressed_tensors/utils/safetensors_load.py,sha256=wo9UirGrGlenBqZeqotvpCT7D5MEdjCo2J3HeRaIFoU,8502
-compressed_tensors_nightly-0.3.3.20240523.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-compressed_tensors_nightly-0.3.3.20240523.dist-info/METADATA,sha256=_c67GXEm0cMZ_AGWhcLqsMZ3hSbFB4KdQ3lL9Dg7M8M,5633
-compressed_tensors_nightly-0.3.3.20240523.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-compressed_tensors_nightly-0.3.3.20240523.dist-info/top_level.txt,sha256=w2i-GyPs2s1UwVxvutSvN_lM22SXC2hQFBmoMcPnV7Y,19
-compressed_tensors_nightly-0.3.3.20240523.dist-info/RECORD,,
+compressed_tensors_nightly-0.3.3.20240524.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+compressed_tensors_nightly-0.3.3.20240524.dist-info/METADATA,sha256=UKjwrUdq2hJGGcA2_ZGO0us811fMjVun9scVSPVXxTI,5633
+compressed_tensors_nightly-0.3.3.20240524.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+compressed_tensors_nightly-0.3.3.20240524.dist-info/top_level.txt,sha256=w2i-GyPs2s1UwVxvutSvN_lM22SXC2hQFBmoMcPnV7Y,19
+compressed_tensors_nightly-0.3.3.20240524.dist-info/RECORD,,
```

